import asyncio
import logging
import uuid
from datetime import datetime
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import json
import os
import shutil
import subprocess

from ..database_enhanced import db_manager
from ..utils.monitoring import PerformanceMonitor
from ..thumbnail_generator import generate_thumbnail
from ..youtube_logic import simulate_roi

logger = logging.getLogger(__name__)

@dataclass
class PipelineResult:
    """
    Represents the result of a pipeline execution.

    Attributes:
        success (bool): True if the pipeline completed successfully, False otherwise.
        pipeline_id (str): Unique identifier for the pipeline execution.
        artifacts (Dict[str, str]): Dictionary of paths or identifiers for generated artifacts.
        execution_time (float): Total execution time in seconds.
        error (Optional[str]): Error message if the pipeline failed.
        metadata (Optional[Dict[str, Any]]): Additional metadata about the pipeline run.
    """
    success: bool
    pipeline_id: str
    artifacts: Dict[str, str]
    execution_time: float
    error: Optional[str] = None
    metadata: Dict[str, Any] = None

@dataclass
class PipelineStage:
    """
    Represents a single stage within the video generation pipeline.

    Attributes:
        name (str): The name of the pipeline stage.
        status (str): Current status of the stage (e.g., "pending", "running", "completed", "failed").
        progress (int): Progress percentage of the stage (0-100).
        start_time (Optional[datetime]): Timestamp when the stage started.
        end_time (Optional[datetime]): Timestamp when the stage ended.
        artifacts (Optional[Dict[str, str]]): Artifacts generated by this stage.
        error (Optional[str]): Error message if the stage failed.
    """
    name: str
    status: str = "pending"
    progress: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    artifacts: Dict[str, str] = None
    error: Optional[str] = None

class EnhancedVideoPipeline:
    """
    Orchestrates the enhanced video generation pipeline from topic to final video.

    This pipeline manages various stages including content generation, script creation,
    thumbnail and audio generation, video assembly, optimization, and finalization.
    It tracks progress, stores artifacts, and logs results to the database.

    Args:
        topic (str): The main topic for the video.
        title (str): The title of the video.
        target_views (int, optional): Target view count for ROI simulation. Defaults to 10000.
        monetization_enabled (bool, optional): Whether monetization should be enabled. Defaults to True.
        quality_level (str, optional): Desired quality level ('low', 'medium', 'high'). Defaults to "high".
        model_type (str, optional): Type of model to use for content generation. Defaults to "openai".
        endpoint (str, optional): Endpoint for model communication. Defaults to "cloud".

    Attributes:
        pipeline_id (str): Unique ID for this pipeline instance.
        stages (List[PipelineStage]): List of defined stages in the pipeline.
        artifacts (Dict[str, str]): Collection of artifacts produced during the pipeline.
        model_type (str): Type of model used for content generation.
        endpoint (str): Endpoint for model communication.
    """
    def __init__(self, topic: str, title: str, target_views: int = 10000,
                 monetization_enabled: bool = True, quality_level: str = "high",
                 model_type: str = "openai", endpoint: str = "cloud"):
        self.pipeline_id = str(uuid.uuid4())
        self.topic = topic
        self.title = title
        self.target_views = target_views
        self.monetization_enabled = monetization_enabled
        self.quality_level = quality_level
        self.model_type = model_type
        self.endpoint = endpoint
        
        # Pipeline configuration
        self.stages = [
            PipelineStage("initialization"),
            PipelineStage("content_generation"),
            PipelineStage("script_creation"),
            PipelineStage("thumbnail_generation"),
            PipelineStage("audio_generation"),
            PipelineStage("video_assembly"),
            PipelineStage("optimization"),
            PipelineStage("finalization")
        ]
        
        self.current_stage_index = 0
        self.artifacts = {}
        self.metadata = {
            "created_at": datetime.utcnow().isoformat(),
            "topic": topic,
            "title": title,
            "target_views": target_views,
            "quality_level": quality_level
        }

        environment = os.getenv("ENVIRONMENT") or os.getenv("APP_ENV") or "production"
        environment = environment.lower()
        allow_placeholders = os.getenv("VIDEO_PIPELINE_ALLOW_PLACEHOLDERS")
        if allow_placeholders is None:
            self.allow_placeholders = environment != "production"
        else:
            self.allow_placeholders = allow_placeholders.lower() in ("1", "true", "yes")

        # Performance tracking
        self.start_time = None
        self.end_time = None
        
    async def execute_full_pipeline(self) -> PipelineResult:
        """
        Executes all stages of the video generation pipeline sequentially.

        Logs progress and results to the database. Handles errors at each stage
        and ensures the pipeline state is updated accordingly.

        Returns:
            PipelineResult: An object containing the outcome of the pipeline execution.
        """
        self.start_time = datetime.utcnow()
        
        try:
            logger.info(f"Starting pipeline execution: {self.pipeline_id}")
            
            # Store initial pipeline state
            await self._store_pipeline_state()
            
            # Execute each stage
            for i, stage in enumerate(self.stages):
                self.current_stage_index = i
                await self._execute_stage(stage)
                
                if stage.status == "failed":
                    raise Exception(f"Stage {stage.name} failed: {stage.error}")
                
                # Update progress
                await self._update_pipeline_progress()
            
            self.end_time = datetime.utcnow()
            execution_time = (self.end_time - self.start_time).total_seconds()
            
            # Store final result
            result = PipelineResult(
                success=True,
                pipeline_id=self.pipeline_id,
                artifacts=self.artifacts,
                execution_time=execution_time,
                metadata=self.metadata
            )
            
            await db_manager.store_pipeline_result(self.pipeline_id, {
                "status": "completed",
                "data": result.artifacts,
                "execution_time": execution_time,
                "artifacts": list(self.artifacts.keys())
            })
            
            logger.info(f"Pipeline completed successfully: {self.pipeline_id}")
            return result
            
        except Exception as e:
            self.end_time = datetime.utcnow()
            execution_time = (self.end_time - self.start_time).total_seconds() if self.start_time else 0
            
            logger.error(f"Pipeline execution failed: {self.pipeline_id} - {e}")
            
            # Store error result
            await db_manager.store_pipeline_error(self.pipeline_id, {
                "error": str(e),
                "stage": self.stages[self.current_stage_index].name if self.current_stage_index < len(self.stages) else "unknown",
                "execution_time": execution_time
            })
            
            return PipelineResult(
                success=False,
                pipeline_id=self.pipeline_id,
                artifacts=self.artifacts,
                execution_time=execution_time,
                error=str(e),
                metadata=self.metadata
            )
    
    async def _execute_stage(self, stage: PipelineStage):
        """
        Executes a specific stage of the pipeline.

        Updates stage status, logs progress, and handles stage-specific logic.
        If a stage fails, it logs the error and re-raises the exception.

        Args:
            stage (PipelineStage): The pipeline stage to execute.
        """
        try:
            stage.start_time = datetime.utcnow()
            stage.status = "running"
            stage.artifacts = {}
            
            logger.info(f"Executing stage: {stage.name}")
            
            # Execute stage-specific logic
            if stage.name == "initialization":
                await self._stage_initialization(stage)
            elif stage.name == "content_generation":
                await self._stage_content_generation(stage)
            elif stage.name == "script_creation":
                await self._stage_script_creation(stage)
            elif stage.name == "thumbnail_generation":
                await self._stage_thumbnail_generation(stage)
            elif stage.name == "audio_generation":
                await self._stage_audio_generation(stage)
            elif stage.name == "video_assembly":
                await self._stage_video_assembly(stage)
            elif stage.name == "optimization":
                await self._stage_optimization(stage)
            elif stage.name == "finalization":
                await self._stage_finalization(stage)
            
            stage.end_time = datetime.utcnow()
            stage.status = "completed"
            stage.progress = 100
            
            # Merge stage artifacts into pipeline artifacts
            if stage.artifacts:
                self.artifacts.update(stage.artifacts)
            
            logger.info(f"Stage {stage.name} completed successfully")
            
        except Exception as e:
            stage.end_time = datetime.utcnow()
            stage.status = "failed"
            stage.error = str(e)
            
            logger.error(f"Stage {stage.name} failed: {e}")
            
            # Store error result
            await db_manager.store_pipeline_error(self.pipeline_id, {
                "error": str(e),
                "stage": stage.name,
                "execution_time": (datetime.utcnow() - stage.start_time).total_seconds() if stage.start_time else 0
            })
            
            raise
    
    async def _stage_initialization(self, stage: PipelineStage):
        """Initialize pipeline resources and validate inputs."""
        try:
            # Validate inputs
            if not self.title or not self.topic:
                raise ValueError("Title and topic are required")
            
            # Create working directories
            work_dir = f"pipeline_work/{self.pipeline_id}"
            os.makedirs(work_dir, exist_ok=True)
            
            stage.artifacts["work_directory"] = work_dir
            stage.progress = 50
            
            # Initialize metadata
            self.metadata.update({
                "work_directory": work_dir,
                "pipeline_version": "2.0",
                "quality_settings": self._get_quality_settings()
            })
            
            stage.progress = 100
            
        except Exception as e:
            logger.error(f"Initialization stage failed: {e}")
            raise
    
    async def _stage_content_generation(self, stage: PipelineStage):
        """Generate content ideas and structure."""
        try:
            # Simulate content generation
            await asyncio.sleep(2)  # Simulate processing time
            
            content_structure = {
                "introduction": f"Welcome to our video about {self.topic}",
                "main_points": [
                    f"Key aspect 1 of {self.topic}",
                    f"Key aspect 2 of {self.topic}",
                    f"Key aspect 3 of {self.topic}"
                ],
                "conclusion": f"Summary of {self.topic} discussion",
                "call_to_action": "Subscribe for more content!"
            }
            
            stage.artifacts["content_structure"] = json.dumps(content_structure)
            stage.progress = 100
            
        except Exception as e:
            logger.error(f"Content generation stage failed: {e}")
            raise
    
    async def _stage_script_creation(self, stage: PipelineStage):
        """Create video script based on content structure."""
        try:
            # Get content structure from previous stage
            content_structure = json.loads(
                self.artifacts.get("content_structure", "{}")
            )
            
            # Generate script
            script_parts = []
            
            # Introduction
            script_parts.append(f"[INTRO] {content_structure.get('introduction', '')}")
            
            # Main content
            for i, point in enumerate(content_structure.get('main_points', []), 1):
                script_parts.append(f"[SECTION {i}] {point}")
            
            # Conclusion
            script_parts.append(f"[OUTRO] {content_structure.get('conclusion', '')}")
            script_parts.append(f"[CTA] {content_structure.get('call_to_action', '')}")
            
            full_script = "\n\n".join(script_parts)
            
            # Save script to file
            work_dir = self.artifacts.get("work_directory")
            script_path = os.path.join(work_dir, "script.txt")
            
            with open(script_path, 'w', encoding='utf-8') as f:
                f.write(full_script)
            
            stage.artifacts["script_path"] = script_path
            stage.artifacts["script_content"] = full_script
            stage.progress = 100
            
        except Exception as e:
            logger.error(f"Script creation stage failed: {e}")
            raise
    
    async def _stage_thumbnail_generation(self, stage: PipelineStage):
        """Generate video thumbnail."""
        try:
            # Generate thumbnail using the thumbnail generator
            thumbnail_result = await generate_thumbnail(
                title=self.title,
                style=self._get_thumbnail_style(),
                colors=self._get_brand_colors(),
                format="png"
            )
            
            stage.artifacts["thumbnail_path"] = thumbnail_result["path"]
            stage.artifacts["thumbnail_style"] = thumbnail_result["style"]
            stage.progress = 100
            
        except Exception as e:
            logger.error(f"Thumbnail generation stage failed: {e}")
            raise
    
    async def _stage_audio_generation(self, stage: PipelineStage):
        """Generate audio narration from script."""
        try:
            script_content = self.artifacts.get("script_content", "")
            work_dir = self.artifacts.get("work_directory")

            if not script_content.strip():
                raise RuntimeError("Script content missing; cannot generate audio.")

            from ..tts_generator import generate_audio

            voice_id = os.getenv("TTS_VOICE_ID", "en-US-Neural2-J")
            speed = float(os.getenv("TTS_SPEED", "1.0"))

            try:
                result = await generate_audio(
                    text=script_content,
                    voice_id=voice_id,
                    speed=speed,
                )
                audio_path = result["path"]
                if work_dir:
                    target = os.path.join(work_dir, os.path.basename(audio_path))
                    if audio_path != target:
                        shutil.copyfile(audio_path, target)
                        audio_path = target
                stage.artifacts["audio_path"] = audio_path
                stage.artifacts["audio_duration"] = result.get("duration")
            except Exception:
                if not self.allow_placeholders:
                    raise
                if not work_dir:
                    raise
                audio_path = os.path.join(work_dir, "narration_placeholder.mp3")
                with open(audio_path, "w") as f:
                    f.write("# Placeholder audio file")
                stage.artifacts["audio_path"] = audio_path
                stage.artifacts["audio_duration"] = 300
            stage.progress = 100
            
        except Exception as e:
            logger.error(f"Audio generation stage failed: {e}")
            raise
    
    async def _stage_video_assembly(self, stage: PipelineStage):
        """Assemble final video from components."""
        try:
            work_dir = self.artifacts.get("work_directory")
            audio_path = self.artifacts.get("audio_path")
            thumbnail_path = self.artifacts.get("thumbnail_path")

            if not work_dir:
                raise RuntimeError("Work directory missing; cannot assemble video.")
            if not audio_path or not thumbnail_path:
                raise RuntimeError("Missing audio or thumbnail for video assembly.")

            ffmpeg_path = shutil.which("ffmpeg")
            if not ffmpeg_path:
                if not self.allow_placeholders:
                    raise RuntimeError("ffmpeg not found; install ffmpeg to assemble videos.")
                ffmpeg_path = None

            video_path = os.path.join(work_dir, "final_video.mp4")
            if ffmpeg_path:
                cmd = [
                    ffmpeg_path,
                    "-y",
                    "-loop", "1",
                    "-i", thumbnail_path,
                    "-i", audio_path,
                    "-c:v", "libx264",
                    "-tune", "stillimage",
                    "-c:a", "aac",
                    "-b:a", "192k",
                    "-pix_fmt", "yuv420p",
                    "-shortest",
                    video_path,
                ]
                result = subprocess.run(cmd, capture_output=True, text=True)
                if result.returncode != 0:
                    if not self.allow_placeholders:
                        raise RuntimeError(f"ffmpeg failed: {result.stderr.strip()}")
                    with open(video_path, "w") as f:
                        f.write("# Placeholder video file")
            else:
                with open(video_path, "w") as f:
                    f.write("# Placeholder video file")

            stage.artifacts["video_path"] = video_path
            stage.artifacts["video_duration"] = stage.artifacts.get("audio_duration")
            stage.artifacts["video_resolution"] = "1920x1080"
            stage.progress = 100
            
        except Exception as e:
            logger.error(f"Video assembly stage failed: {e}")
            raise
    
    async def _stage_optimization(self, stage: PipelineStage):
        """Optimize video for platform and performance."""
        try:
            video_path = self.artifacts.get("video_path")
            
            # Simulate optimization
            await asyncio.sleep(2)
            
            # Generate SEO metadata
            seo_metadata = {
                "title": self.title,
                "description": f"Learn about {self.topic} in this comprehensive video.",
                "tags": [self.topic, "tutorial", "educational"],
                "category": "Education"
            }
            
            # Calculate ROI simulation
            roi_data = simulate_roi(
                views=self.target_views,
                cpm=5.0,
                engagement_rate=0.05,
                subscriber_rate=0.02
            )
            
            stage.artifacts["seo_metadata"] = json.dumps(seo_metadata)
            stage.artifacts["roi_projection"] = json.dumps(roi_data)
            stage.progress = 100
            
        except Exception as e:
            logger.error(f"Optimization stage failed: {e}")
            raise
    
    async def _stage_finalization(self, stage: PipelineStage):
        """Finalize video and prepare for upload."""
        try:
            # Collect all artifacts
            final_artifacts = {
                "video_path": self.artifacts.get("video_path"),
                "thumbnail_path": self.artifacts.get("thumbnail_path"),
                "script_path": self.artifacts.get("script_path"),
                "audio_path": self.artifacts.get("audio_path"),
                "seo_metadata": self.artifacts.get("seo_metadata"),
                "roi_projection": self.artifacts.get("roi_projection")
            }
            
            # Store video idea in database
            from ..database import insert_idea
            
            seo_data = json.loads(self.artifacts.get("seo_metadata", "{}"))
            roi_data = json.loads(self.artifacts.get("roi_projection", "{}"))
            
            idea_id = insert_idea(
                title=self.title,
                category=self.topic,
                expected_views=self.target_views,
                metadata={
                    "pipeline_id": self.pipeline_id,
                    "roi_projection": roi_data,
                    "quality_level": self.quality_level
                },
                tags=seo_data.get("tags", []),
                script=self.artifacts.get("script_content"),
                thumbnail_path=self.artifacts.get("thumbnail_path"),
                audio_path=self.artifacts.get("audio_path")
            )
            
            stage.artifacts["idea_id"] = str(idea_id)
            stage.artifacts["final_artifacts"] = json.dumps(final_artifacts)
            stage.progress = 100
            
            # Update metadata
            self.metadata["idea_id"] = idea_id
            self.metadata["finalized_at"] = datetime.utcnow().isoformat()
            
        except Exception as e:
            logger.error(f"Finalization stage failed: {e}")
            raise
    
    def _get_quality_settings(self) -> Dict[str, Any]:
        """Get quality settings based on quality level."""
        quality_configs = {
            "low": {
                "video_bitrate": "1000k",
                "audio_bitrate": "128k",
                "resolution": "720p",
                "fps": 24
            },
            "medium": {
                "video_bitrate": "2500k",
                "audio_bitrate": "192k",
                "resolution": "1080p",
                "fps": 30
            },
            "high": {
                "video_bitrate": "5000k",
                "audio_bitrate": "320k",
                "resolution": "1080p",
                "fps": 60
            }
        }
        
        return quality_configs.get(self.quality_level, quality_configs["medium"])
    
    def _get_thumbnail_style(self) -> str:
        """Get thumbnail style based on topic."""
        style_mapping = {
            "tech": "modern",
            "gaming": "dynamic",
            "education": "clean",
            "entertainment": "colorful",
            "business": "professional"
        }
        
        return style_mapping.get(self.topic.lower(), "modern")
    
    def _get_brand_colors(self) -> List[str]:
        """Get brand colors for thumbnail."""
        return ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FFEAA7"]
    
    async def _store_pipeline_state(self):
        """Store current pipeline state to database."""
        try:
            pipeline_data = {
                "pipeline_id": self.pipeline_id,
                "status": "running",
                "stage": self.stages[self.current_stage_index].name,
                "progress": self._calculate_overall_progress(),
                "data": self.metadata
            }
            
            await db_manager.store_pipeline_result(self.pipeline_id, pipeline_data)
            
        except Exception as e:
            logger.error(f"Failed to store pipeline state: {e}")
    
    async def _update_pipeline_progress(self):
        """Update pipeline progress in database."""
        try:
            overall_progress = self._calculate_overall_progress()
            current_stage = self.stages[self.current_stage_index]
            
            pipeline_data = {
                "status": "running",
                "stage": current_stage.name,
                "progress": overall_progress,
                "data": self.metadata
            }
            
            await db_manager.store_pipeline_result(self.pipeline_id, pipeline_data)
            
        except Exception as e:
            logger.error(f"Failed to update pipeline progress: {e}")
    
    def _calculate_overall_progress(self) -> int:
        """Calculate overall pipeline progress percentage."""
        try:
            total_stages = len(self.stages)
            completed_stages = sum(1 for stage in self.stages if stage.status == "completed")
            
            if self.current_stage_index < total_stages:
                current_stage_progress = self.stages[self.current_stage_index].progress / 100
                overall_progress = (completed_stages + current_stage_progress) / total_stages * 100
            else:
                overall_progress = 100
            
            return int(overall_progress)
            
        except Exception as e:
            logger.error(f"Progress calculation failed: {e}")
            return 0
    
    async def get_pipeline_status(self) -> Dict[str, Any]:
        """Get current pipeline status."""
        try:
            return {
                "pipeline_id": self.pipeline_id,
                "overall_progress": self._calculate_overall_progress(),
                "current_stage": self.stages[self.current_stage_index].name if self.current_stage_index < len(self.stages) else "completed",
                "stages": [
                    {
                        "name": stage.name,
                        "status": stage.status,
                        "progress": stage.progress,
                        "start_time": stage.start_time.isoformat() if stage.start_time else None,
                        "end_time": stage.end_time.isoformat() if stage.end_time else None,
                        "error": stage.error
                    }
                    for stage in self.stages
                ],
                "artifacts": list(self.artifacts.keys()),
                "metadata": self.metadata
            }
            
        except Exception as e:
            logger.error(f"Failed to get pipeline status: {e}")
            return {"error": str(e)}
    
    async def cleanup(self):
        """Clean up pipeline resources."""
        try:
            work_dir = self.artifacts.get("work_directory")
            if work_dir and os.path.exists(work_dir):
                import shutil
                shutil.rmtree(work_dir, ignore_errors=True)
                logger.info(f"Cleaned up work directory: {work_dir}")
                
        except Exception as e:
            logger.error(f"Pipeline cleanup failed: {e}")
